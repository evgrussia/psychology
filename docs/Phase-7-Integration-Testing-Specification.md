# Phase 7: Integration & Testing — Техническая спецификация

**Проект:** «Эмоциональный баланс»  
**Версия:** v1.0  
**Дата:** 2026-01-26  
**Статус:** В работе  
**Основано на:** `docs/Development-Phase-Plan.md`, `docs/NFR-SLO-SLI-Performance-Security-Scalability.md`, `docs/security/security-requirements.md`, `docs/Accessibility-A11y-Requirements.md`, `docs/user-flows-cjm.md`, `docs/Roadmap-Backlog.md`

---

## 1) Назначение документа

Этот документ описывает **детальную техническую спецификацию** для Phase 7: Integration & Testing. Он определяет:

- **Область тестирования** (что тестируем)
- **Методологию и подходы** (как тестируем)
- **Инструменты и инфраструктуру** (чем тестируем)
- **Критерии готовности** (когда считаем готовым)
- **План выполнения** (последовательность работ)
- **Отчетность и метрики** (как измеряем прогресс)

**Целевая аудитория:** QA инженеры, DevOps, Security специалисты, разработчики, Product Owner.

---

## 2) Цели Phase 7

### 2.1 Основные цели

1. **Верификация интеграции** всех компонентов системы (backend, frontend, внешние сервисы)
2. **Проверка ключевых пользовательских сценариев** (E2E) на соответствие требованиям
3. **Валидация производительности** согласно SLO (NFR-SLO-SLI)
4. **Проверка безопасности** согласно security requirements
5. **Проверка доступности** согласно WCAG 2.2 AA
6. **Исправление критичных багов** перед Go Live

### 2.2 Критерии успеха Phase 7

- ✅ Все интеграционные тесты проходят (≥95% pass rate)
- ✅ Все E2E тесты ключевых сценариев проходят (100% pass rate для P0)
- ✅ Нагрузочные тесты подтверждают соответствие SLO
- ✅ Security audit не выявил критичных уязвимостей (0 критичных, ≤3 высоких)
- ✅ A11y проверка подтверждает WCAG 2.2 AA (≥95% соответствие)
- ✅ Критичные баги исправлены (0 блокеров, ≤5 высоких)
- ✅ Все отчеты сгенерированы и задокументированы

---

## 3) Область тестирования

### 3.1 Компоненты системы

#### 3.1.1 Backend API
- **REST API v1** (все endpoints)
- **Аутентификация и авторизация** (JWT, RBAC)
- **Domain Layer** (Use Cases, Domain Services)
- **Infrastructure Layer** (Repositories, Integrations)
- **Event Bus** (Domain Events)

#### 3.1.2 Frontend
- **Публичный Web** (главная, лендинги, контент)
- **Интерактивы** (квизы, навигатор, скрипты границ, ритуалы)
- **Booking Flow** (услуга → слот → анкета → согласия → оплата)
- **Client Cabinet** (встречи, дневники, экспорт, управление данными)
- **Admin Panel** (все разделы)

#### 3.1.3 Интеграции
- **Google Calendar** (двусторонняя синхронизация слотов)
- **ЮKassa** (создание платежей, webhooks, статусы)
- **Telegram Bot API** (бот, deep links, онбординг)
- **Email** (уведомления, подтверждения)

#### 3.1.4 Инфраструктура
- **База данных** (PostgreSQL, миграции, транзакции)
- **Медиа-хранилище** (загрузка/отдача файлов)
- **CI/CD Pipeline** (сборка, деплой, тесты)
- **Мониторинг и логирование** (метрики, алерты)

### 3.2 Ключевые пользовательские сценарии (E2E)

Согласно `docs/user-flows-cjm.md`, тестируем следующие сценарии:

#### G1 — Быстрый старт пользы
**Путь:** Главная → выбор состояния → запуск интерактива → результат → CTA

**Шаги:**
1. Открытие главной страницы
2. Выбор карточки состояния (тревога/выгорание/отношения/самооценка/границы)
3. Запуск интерактива (упражнение/мини-диагностика)
4. Прохождение интерактива до результата
5. Просмотр результата и CTA (Telegram/запись)

**Критерии успеха:**
- LCP p75 ≤ 2.5s для главной
- INP p75 ≤ 200ms для интерактивов
- Результат отображается корректно
- CTA работают (deep links, переходы)

#### G2 — Запись (Booking Flow)
**Путь:** Выбор услуги → выбор слота → анкета → согласия → оплата → подтверждение

**Шаги:**
1. Выбор услуги (формат, длительность, правила)
2. Выбор слота в календаре (таймзона, доступность)
3. Заполнение анкеты (5-8 полей, валидация)
4. Согласия (раздельные, ссылки на документы)
5. Оплата через ЮKassa (создание платежа, редирект)
6. Обработка webhook (статус оплаты)
7. Подтверждение записи (email, уведомление, напоминания)

**Критерии успеха:**
- Успешное подтверждение брони при корректных условиях (SLO: 99.5%)
- Защита от гонок (один слот нельзя подтвердить дважды)
- Корректная синхронизация с Google Calendar
- Идемпотентная обработка webhooks
- Время ответа API p95 ≤ 800ms

**Альтернативные пути:**
- Нет слотов → лист ожидания / Telegram-консьерж
- Конфликт брони → честное сообщение + выбор нового слота
- Ошибка оплаты → бережная ошибка + повтор/альтернатива

#### G3 — Telegram-связка
**Путь:** CTA "получить план/сохранить" → deep link → онбординг → серия/план

**Шаги:**
1. Клик CTA на сайте (с параметрами deep link)
2. Переход в Telegram (корректный deep link)
3. Онбординг бота (30-60 сек: тема → цель → частота)
4. Получение первого ресурса/плана
5. Серия сообщений (3-7 сообщений) или челлендж (7 дней)

**Критерии успеха:**
- Deep link корректно передает контекст
- Онбординг завершается успешно
- Серия доставляется согласно настройкам
- Отписка работает корректно

#### G4 — Админ-операции
**Путь:** Вход в админку → открытие раздела → выполнение операции → сохранение

**Шаги:**
1. Аутентификация (MFA для owner/assistant)
2. Навигация по разделам (расписание, контент, CRM, модерация)
3. Выполнение операции (создание/редактирование/удаление)
4. Аудит-лог записывает действие
5. Сохранение изменений

**Критерии успеха:**
- RBAC работает корректно (права проверяются на сервере)
- MFA обязательна для админов
- Аудит-лог записывает критичные действия
- Операции выполняются атомарно

### 3.3 Дополнительные сценарии

- **Контент:** чтение статьи → "попробовать сейчас" → сохранение/Telegram
- **Client Cabinet:** вход → просмотр встреч → заполнение дневника → экспорт PDF
- **UGC:** отправка анонимного вопроса → модерация → публикация/отклонение
- **Кризисный режим:** триггер → экстренная помощь → безопасная навигация

---

## 4) Методология тестирования

### 4.1 Интеграционное тестирование

#### 4.1.1 Цель
Проверить взаимодействие между компонентами системы (слои Clean Architecture, интеграции с внешними сервисами).

#### 4.1.2 Подход
- **Пирамида тестов:** Unit (70%) → Integration (20%) → E2E (10%)
- **Изоляция:** каждый тест независим, использует test fixtures
- **Моки:** внешние сервисы (Google Calendar, ЮKassa, Telegram) мокируются
- **Тестовые данные:** отдельная БД для тестов, seed data для каждого теста

#### 4.1.3 Область покрытия

**Backend Integration Tests:**

1. **Domain → Infrastructure**
   - Repository implementations (сохранение/загрузка агрегатов)
   - Транзакции и консистентность данных
   - Миграции БД

2. **Application → Domain**
   - Use Cases вызывают Domain Services корректно
   - Domain Events публикуются
   - Валидация бизнес-правил

3. **Presentation → Application**
   - API endpoints вызывают Use Cases
   - Serializers корректно преобразуют DTOs
   - Обработка ошибок

4. **Infrastructure → External Services**
   - Google Calendar API (синхронизация слотов)
   - ЮKassa API (создание платежей, обработка webhooks)
   - Telegram Bot API (отправка сообщений, deep links)
   - Email (отправка уведомлений)

**Frontend Integration Tests:**

1. **Components → API**
   - API клиент корректно вызывает endpoints
   - Обработка состояний (loading/error/success)
   - Кэширование и оптимистичные обновления

2. **Components → Design System**
   - Компоненты используют Design System корректно
   - Стили применяются правильно
   - Адаптивность (responsive)

3. **Routing & Navigation**
   - Роутинг работает корректно
   - Навигация между страницами
   - Deep links обрабатываются

#### 4.1.4 Инструменты

**Backend:**
- **pytest** + **pytest-django** (Python/Django)
- **factory-boy** (test fixtures)
- **responses** (моки HTTP запросов)
- **freezegun** (моки времени)

**Frontend:**
- **Jest** + **React Testing Library** (React компоненты)
- **MSW (Mock Service Worker)** (моки API)
- **Playwright** (компонентное тестирование)

#### 4.1.5 Критерии покрытия

- **Минимальное покрытие:** ≥80% для критичных модулей
- **Целевое покрытие:** ≥90% для Domain Layer
- **Обязательное покрытие:** 100% для Use Cases (P0)

### 4.2 E2E тестирование

#### 4.2.1 Цель
Проверить полные пользовательские сценарии от начала до конца, включая взаимодействие с реальными внешними сервисами (staging окружение).

#### 4.2.2 Подход
- **Реалистичные данные:** тестовые данные максимально близки к production
- **Внешние сервисы:** staging окружения (Google Calendar test account, ЮKassa sandbox, Telegram test bot)
- **Изоляция:** каждый тест очищает данные после выполнения
- **Параллелизация:** тесты могут выполняться параллельно (без конфликтов)

#### 4.2.3 Приоритеты тестов

**P0 (критичные, обязательны):**
- G1: Быстрый старт пользы
- G2: Запись (полный flow)
- G3: Telegram-связка
- G4: Админ-операции

**P1 (важные, желательны):**
- Контент → сохранение/Telegram
- Client Cabinet → дневники → экспорт
- UGC → модерация
- Кризисный режим

#### 4.2.4 Инструменты

- **Playwright** (основной инструмент для E2E)
  - Поддержка Chrome, Firefox, Safari
  - Автоматические скриншоты при ошибках
  - Видео записи (опционально)
  - Trace viewer для отладки

- **Cypress** (альтернатива, если требуется)
  - Time-travel debugging
  - Автоматические скриншоты

#### 4.2.5 Структура E2E тестов

```
e2e/
├── fixtures/
│   ├── users.json          # Тестовые пользователи
│   ├── services.json       # Тестовые услуги
│   └── content.json        # Тестовый контент
├── helpers/
│   ├── api.ts              # API хелперы
│   ├── auth.ts             # Аутентификация
│   └── assertions.ts       # Кастомные assertions
├── scenarios/
│   ├── g1-quick-start.spec.ts
│   ├── g2-booking.spec.ts
│   ├── g3-telegram.spec.ts
│   └── g4-admin.spec.ts
└── utils/
    ├── cleanup.ts          # Очистка данных
    └── seed.ts             # Seed данных
```

#### 4.2.6 Критерии успеха

- **100% pass rate** для P0 тестов
- **≥95% pass rate** для всех E2E тестов
- **Время выполнения:** полный набор P0 тестов ≤ 30 минут
- **Стабильность:** flaky тесты ≤ 2%

### 4.3 Нагрузочное тестирование

#### 4.3.1 Цель
Проверить соответствие системы требованиям производительности согласно SLO (см. `docs/NFR-SLO-SLI-Performance-Security-Scalability.md`).

#### 4.3.2 Методология

**Типы нагрузочных тестов:**

1. **Baseline Test** (базовая нагрузка)
   - Нормальная нагрузка (50-100 одновременных пользователей)
   - Проверка стабильности системы

2. **Load Test** (рабочая нагрузка)
   - Ожидаемая нагрузка (100-200 одновременных пользователей)
   - Проверка соответствия SLO

3. **Stress Test** (пиковая нагрузка)
   - Превышение ожидаемой нагрузки (200-500 одновременных пользователей)
   - Проверка деградации и восстановления

4. **Spike Test** (резкий рост)
   - Резкое увеличение нагрузки (0 → 500 пользователей за 1 минуту)
   - Проверка устойчивости к скачкам

5. **Endurance Test** (длительная нагрузка)
   - Устойчивая нагрузка в течение 1-2 часов
   - Проверка утечек памяти, деградации производительности

#### 4.3.3 Сценарии нагрузки

**Сценарий 1: Публичный Web (G1)**
- **Нагрузка:** 50-100 одновременных пользователей
- **Действия:** просмотр главной, лендингов, запуск интерактивов
- **Метрики:**
  - LCP p75 ≤ 2.5s
  - INP p75 ≤ 200ms
  - TTFB p95 ≤ 800ms
  - Error rate ≤ 0.1%

**Сценарий 2: Booking Flow (G2)**
- **Нагрузка:** 20-50 одновременных пользователей
- **Действия:** выбор услуги, выбор слота, заполнение анкеты, оплата
- **Метрики:**
  - API p95 ≤ 800ms (booking endpoints)
  - Success rate ≥ 99.5% (успешные подтверждения)
  - Защита от гонок (0 дублирующих броней)

**Сценарий 3: API (общая нагрузка)**
- **Нагрузка:** 100-200 одновременных запросов
- **Действия:** смешанные запросы (read/write)
- **Метрики:**
  - Read operations p95 ≤ 300ms
  - Write operations p95 ≤ 800ms
  - Error rate ≤ 0.1%

**Сценарий 4: Интеграции (webhooks)**
- **Нагрузка:** 50-100 webhooks/минуту
- **Действия:** обработка webhooks от ЮKassa, Google Calendar
- **Метрики:**
  - Webhook processing p95 ≤ 500ms
  - Идемпотентность (0 дублирующих обработок)
  - Retry logic работает корректно

#### 4.3.4 Инструменты

- **k6** (основной инструмент)
  - Scripting на JavaScript
  - Метрики в реальном времени
  - Интеграция с Grafana/InfluxDB

- **Locust** (альтернатива)
  - Python-based
  - Web UI для мониторинга

- **JMeter** (для сложных сценариев)
  - GUI для создания тестов
  - Поддержка различных протоколов

#### 4.3.5 Инфраструктура для нагрузочного тестирования

- **Тестовое окружение:** staging, максимально близкое к production
- **Мониторинг:** Grafana + Prometheus (метрики в реальном времени)
- **Логирование:** централизованные логи (ELK stack или аналоги)

#### 4.3.6 Критерии успеха

- **Все SLO выполнены** (см. раздел 5.1)
- **Система стабильна** под ожидаемой нагрузкой
- **Деградация graceful** при превышении нагрузки
- **Восстановление** после снятия нагрузки ≤ 5 минут

### 4.4 Security Audit (проверка безопасности)

#### 4.4.1 Цель
Проверить соответствие системы требованиям безопасности согласно `docs/security/security-requirements.md`.

#### 4.4.2 Область проверки

**1. Authentication & Authorization**
- [ ] Пароли: требования к сложности, хеширование (Argon2id/bcrypt)
- [ ] MFA: обязательна для админов, TOTP работает корректно
- [ ] Сессии: timeout, concurrent sessions, token expiry
- [ ] RBAC: права проверяются на сервере, принцип наименьших привилегий

**2. Data Protection**
- [ ] Шифрование at rest: БД, файлы, бэкапы
- [ ] Шифрование in transit: TLS 1.3 (минимум 1.2), HSTS
- [ ] Обработка PII: маскирование в логах, не отправка в аналитику
- [ ] Обработка P2 данных: шифрование, минимальное хранение

**3. API Security**
- [ ] Rate limiting: корректные лимиты для всех endpoint типов
- [ ] Input validation: все входные данные валидируются
- [ ] Output encoding: корректное экранирование
- [ ] CORS: правильная настройка для фронтенда
- [ ] Webhook security: валидация подписей, идемпотентность

**4. Infrastructure Security**
- [ ] Network security: VPC, security groups, WAF (если есть)
- [ ] Secrets management: секреты в secrets manager, не в коде
- [ ] Container security: минимальные образы, no root users
- [ ] Database security: изоляция сети, минимальные права

**5. Secure Development**
- [ ] Static analysis (SAST): Bandit, safety, pip-audit
- [ ] Dependency scanning: регулярное сканирование, фиксация версий
- [ ] Code review: обязательный для всех изменений
- [ ] Secure coding: валидация, экранирование, обработка ошибок

**6. OWASP Top 10**
- [ ] A01: Broken Access Control (IDOR, неправильные права)
- [ ] A02: Cryptographic Failures (неправильное шифрование)
- [ ] A03: Injection (SQLi, XSS, Command Injection)
- [ ] A04: Insecure Design (архитектурные уязвимости)
- [ ] A05: Security Misconfiguration (неправильная конфигурация)
- [ ] A06: Vulnerable Components (уязвимые зависимости)
- [ ] A07: Authentication Failures (слабые пароли, сессии)
- [ ] A08: Software and Data Integrity (supply chain attacks)
- [ ] A09: Logging Failures (недостаточное логирование)
- [ ] A10: SSRF (Server-Side Request Forgery)

#### 4.4.3 Инструменты

**Автоматизированные:**
- **OWASP ZAP** (динамическое сканирование)
- **Bandit** (статический анализ Python)
- **safety / pip-audit** (сканирование зависимостей)
- **npm audit** (сканирование npm зависимостей)
- **Snyk** (комплексное сканирование)

**Ручные проверки:**
- Code review (безопасность)
- Penetration testing (опционально для Release 1)
- Manual security testing (критичные endpoints)

#### 4.4.4 Критерии успеха

- **0 критичных уязвимостей**
- **≤3 высоких уязвимостей** (с планом исправления)
- **Все требования из security-requirements.md выполнены**
- **OWASP Top 10 проверены** (нет известных уязвимостей)

### 4.5 Accessibility (A11y) проверка

#### 4.5.1 Цель
Проверить соответствие системы требованиям доступности WCAG 2.2 AA согласно `docs/Accessibility-A11y-Requirements.md`.

#### 4.5.2 Область проверки

**1. Клавиатурная навигация**
- [ ] Все интерактивные элементы доступны с Tab/Shift+Tab
- [ ] Порядок фокуса логичен (сверху-вниз, слева-направо)
- [ ] Skip-link присутствует на всех публичных страницах
- [ ] Модалки/оверлеи: focus trap, Esc закрывает, возврат фокуса на триггер
- [ ] Аккордеоны: кнопки доступны, aria-expanded корректно

**2. Фокус**
- [ ] Видимый фокус на всех интерактивных элементах (focus-visible)
- [ ] Толщина обводки ≥ 3px, offset ≥ 2-3px
- [ ] Фокус не перекрывается тенями/оверлеями
- [ ] Контраст фокуса ≥ 3:1

**3. Контраст и цвета**
- [ ] Обычный текст: контраст ≥ 4.5:1
- [ ] Крупный текст: контраст ≥ 3:1
- [ ] UI элементы: контраст ≥ 3:1
- [ ] Цвет не единственный носитель смысла (ошибки, ссылки)
- [ ] Ссылки различимы не только цветом (underline)

**4. Семантика и screen reader**
- [ ] Корректные landmarks (header, nav, main, footer)
- [ ] Иерархия заголовков (один h1, без пропусков)
- [ ] Правильные элементы (button для действий, a для навигации)
- [ ] ARIA атрибуты корректны (не дублируют нативную семантику)
- [ ] Live regions для динамических обновлений

**5. Формы**
- [ ] Каждый контрол имеет label
- [ ] Ошибки связаны через aria-describedby
- [ ] aria-invalid="true" для ошибочных полей
- [ ] Required поля обозначены понятно
- [ ] Фокус переводится на первую ошибку после сабмита

**6. Медиа**
- [ ] Все содержательные изображения имеют alt-text
- [ ] Декоративные изображения: alt=""
- [ ] Видео: субтитры (если есть)

**7. Анимации**
- [ ] Уважается prefers-reduced-motion
- [ ] Нет мерцаний, провоцирующих фоточувствительность

**8. Touch targets (mobile)**
- [ ] Минимальный размер: 44×44 px
- [ ] Расстояние между тач-таргетами: ≥ 8 px

#### 4.5.3 Инструменты

**Автоматизированные:**
- **axe DevTools** (интеграция в браузер)
- **Lighthouse Accessibility** (в CI/CD)
- **WAVE** (Web Accessibility Evaluation Tool)
- **Pa11y** (командная строка, CI/CD)

**Ручные проверки:**
- **NVDA** (Windows screen reader)
- **VoiceOver** (macOS/iOS screen reader)
- **Клавиатурная навигация** (только Tab/Enter/Space/Esc)
- **High contrast mode** (Windows/macOS)

#### 4.5.4 Критерии успеха

- **≥95% соответствие WCAG 2.2 AA** (автоматические проверки)
- **100% ключевых сценариев доступны с клавиатуры**
- **100% ключевых сценариев доступны через screen reader**
- **Все формы проходят проверку доступности**
- **Контраст всех текстов и UI элементов соответствует требованиям**

### 4.6 Исправление багов

#### 4.6.1 Цель
Исправить все найденные баги согласно приоритетам и обеспечить стабильность системы перед Go Live.

#### 4.6.2 Классификация багов

**Severity Levels:**

- **Blocker (P0):** Система не работает, критичный функционал недоступен
  - Примеры: нельзя записаться, оплата не работает, админка недоступна
  - **Требование:** исправить немедленно, блокирует релиз

- **Critical (P1):** Критичный функционал работает частично или с серьезными ограничениями
  - Примеры: потеря данных, неправильные расчеты, серьезные проблемы безопасности
  - **Требование:** исправить до релиза, может блокировать релиз

- **High (P2):** Важный функционал работает, но с заметными проблемами
  - Примеры: UI баги, проблемы с производительностью, проблемы с доступностью
  - **Требование:** исправить до релиза или в hotfix после релиза

- **Medium (P3):** Незначительные проблемы, не влияют на основной функционал
  - Примеры: мелкие UI баги, улучшения UX
  - **Требование:** исправить в следующем релизе

- **Low (P4):** Косметические проблемы, улучшения
  - Примеры: опечатки, мелкие стилистические проблемы
  - **Требование:** исправить по возможности

#### 4.6.3 Процесс исправления

1. **Обнаружение:** баг фиксируется в issue tracker (Jira/Linear/YouTrack)
2. **Триаж:** присваивается severity, назначается разработчик
3. **Исправление:** разработчик исправляет баг, пишет тест (если возможно)
4. **Code review:** изменения проходят code review
5. **Тестирование:** QA проверяет исправление
6. **Закрытие:** баг закрывается после подтверждения исправления

#### 4.6.4 Критерии успеха

- **0 блокеров (P0)**
- **≤5 критичных (P1)** с планом исправления до релиза
- **Все высокие (P2)** исправлены или имеют workaround
- **Регрессионное тестирование** пройдено после исправлений

---

## 5) Критерии готовности (Definition of Done)

### 5.1 SLO соответствие

Согласно `docs/NFR-SLO-SLI-Performance-Security-Scalability.md`:

**Availability:**
- ✅ Публичный Web: 99.9% (43 мин "плохих минут" в месяц)
- ✅ Backend API: 99.9%
- ✅ Booking: 99.5% (успешные подтверждения)
- ✅ Payments: 99.9% (идемпотентная обработка)
- ✅ Telegram bot: 99.5%
- ✅ Admin panel: 99.5%

**Performance (Web):**
- ✅ LCP p75 ≤ 2.5s (главная/лендинги/статьи)
- ✅ INP p75 ≤ 200ms (интерактивы)
- ✅ TTFB p95 ≤ 800ms (RUM), ≤ 400ms (synthetic)

**Performance (API):**
- ✅ Read operations: p95 ≤ 300ms
- ✅ Booking: p95 ≤ 800ms
- ✅ Webhooks: p95 ≤ 500ms
- ✅ Error rate: ≤ 0.1%

### 5.2 Тестовое покрытие

- ✅ Unit tests: ≥80% покрытие для критичных модулей
- ✅ Integration tests: все критичные интеграции покрыты
- ✅ E2E tests: 100% pass rate для P0 сценариев
- ✅ Flaky tests: ≤ 2%

### 5.3 Безопасность

- ✅ 0 критичных уязвимостей
- ✅ ≤3 высоких уязвимостей (с планом исправления)
- ✅ Все требования из security-requirements.md выполнены
- ✅ OWASP Top 10 проверены

### 5.4 Доступность

- ✅ ≥95% соответствие WCAG 2.2 AA (автоматические проверки)
- ✅ 100% ключевых сценариев доступны с клавиатуры
- ✅ 100% ключевых сценариев доступны через screen reader
- ✅ Контраст всех элементов соответствует требованиям

### 5.5 Баги

- ✅ 0 блокеров (P0)
- ✅ ≤5 критичных (P1) с планом исправления
- ✅ Все высокие (P2) исправлены или имеют workaround

### 5.6 Документация

- ✅ Все отчеты сгенерированы
- ✅ Баги задокументированы в issue tracker
- ✅ Метрики задокументированы
- ✅ Известные ограничения задокументированы

---

## 6) План выполнения

### 6.1 Этапы Phase 7

#### Этап 1: Подготовка инфраструктуры (1-2 дня)
- [ ] Настройка тестового окружения (staging)
- [ ] Настройка CI/CD для автоматических тестов
- [ ] Настройка инструментов тестирования (Playwright, k6, OWASP ZAP)
- [ ] Подготовка тестовых данных и fixtures
- [ ] Настройка мониторинга и логирования

#### Этап 2: Интеграционное тестирование (3-5 дней)
- [ ] Написание/обновление интеграционных тестов (Backend)
- [ ] Написание/обновление интеграционных тестов (Frontend)
- [ ] Запуск тестов, исправление найденных проблем
- [ ] Достижение целевого покрытия (≥80%)

#### Этап 3: E2E тестирование (5-7 дней)
- [ ] Написание/обновление E2E тестов для P0 сценариев
- [ ] Написание/обновление E2E тестов для P1 сценариев
- [ ] Запуск тестов, исправление найденных проблем
- [ ] Достижение 100% pass rate для P0

#### Этап 4: Нагрузочное тестирование (3-5 дней)
- [ ] Создание сценариев нагрузки (k6 scripts)
- [ ] Запуск baseline/load/stress тестов
- [ ] Анализ результатов, выявление узких мест
- [ ] Оптимизация производительности (если требуется)
- [ ] Повторное тестирование до соответствия SLO

#### Этап 5: Security Audit (3-5 дней)
- [ ] Автоматизированное сканирование (OWASP ZAP, Bandit, dependency scanning)
- [ ] Ручная проверка критичных endpoints
- [ ] Проверка соответствия security-requirements.md
- [ ] Исправление найденных уязвимостей
- [ ] Повторное сканирование для подтверждения исправлений

#### Этап 6: A11y проверка (2-3 дня)
- [ ] Автоматизированная проверка (axe, Lighthouse, Pa11y)
- [ ] Ручная проверка с клавиатуры
- [ ] Ручная проверка с screen reader (NVDA/VoiceOver)
- [ ] Исправление найденных проблем
- [ ] Повторная проверка для подтверждения исправлений

#### Этап 7: Исправление багов (5-10 дней, параллельно с другими этапами)
- [ ] Триаж багов (приоритизация)
- [ ] Исправление блокеров (P0) немедленно
- [ ] Исправление критичных (P1) до релиза
- [ ] Исправление высоких (P2) или создание workaround
- [ ] Регрессионное тестирование после исправлений

#### Этап 8: Финальная проверка и отчетность (2-3 дня)
- [ ] Финальный прогон всех тестов
- [ ] Генерация отчетов
- [ ] Документирование результатов
- [ ] Подготовка к Go Live

### 6.2 Временные рамки

**Общая оценка:** L (2-4 недели)

**Детализация:**
- Подготовка: 1-2 дня
- Интеграционное тестирование: 3-5 дней
- E2E тестирование: 5-7 дней
- Нагрузочное тестирование: 3-5 дней
- Security Audit: 3-5 дней
- A11y проверка: 2-3 дня
- Исправление багов: 5-10 дней (параллельно)
- Финальная проверка: 2-3 дня

**Параллелизация:**
- Security Audit и A11y проверка могут выполняться параллельно
- Исправление багов выполняется параллельно с другими этапами
- Нагрузочное тестирование может выполняться параллельно с Security/A11y

### 6.3 Зависимости

**Входные зависимости:**
- Phase 1-6 завершены (Platform, Domain, Infrastructure, Application, Presentation, Frontend)
- Staging окружение настроено и доступно
- Внешние сервисы имеют staging окружения (Google Calendar test account, ЮKassa sandbox, Telegram test bot)

**Выходные зависимости:**
- Phase 8 (Deployment & Go Live) зависит от завершения Phase 7

---

## 7) Инструменты и инфраструктура

### 7.1 Инструменты тестирования

#### Backend Testing
- **pytest** + **pytest-django** (unit/integration tests)
- **factory-boy** (test fixtures)
- **responses** (HTTP моки)
- **freezegun** (time моки)
- **coverage.py** (покрытие кода)

#### Frontend Testing
- **Jest** + **React Testing Library** (unit/component tests)
- **MSW (Mock Service Worker)** (API моки)
- **Playwright** (E2E tests, component tests)

#### Load Testing
- **k6** (основной инструмент)
- **Locust** (альтернатива)
- **JMeter** (для сложных сценариев)

#### Security Testing
- **OWASP ZAP** (динамическое сканирование)
- **Bandit** (статический анализ Python)
- **safety / pip-audit** (сканирование зависимостей)
- **npm audit** (сканирование npm зависимостей)
- **Snyk** (комплексное сканирование)

#### Accessibility Testing
- **axe DevTools** (браузерное расширение)
- **Lighthouse** (в CI/CD)
- **WAVE** (Web Accessibility Evaluation Tool)
- **Pa11y** (командная строка, CI/CD)
- **NVDA** (Windows screen reader)
- **VoiceOver** (macOS/iOS screen reader)

### 7.2 Инфраструктура

#### Тестовые окружения
- **Staging:** максимально близкое к production
  - База данных (PostgreSQL)
  - Медиа-хранилище
  - Внешние сервисы (staging accounts)

#### CI/CD
- **GitHub Actions / GitLab CI / Jenkins** (автоматические тесты)
- **Test reports:** интеграция с issue tracker
- **Coverage reports:** автоматическая генерация отчетов

#### Мониторинг
- **Grafana + Prometheus** (метрики в реальном времени)
- **ELK Stack / Loki** (централизованные логи)
- **Sentry** (отслеживание ошибок)

### 7.3 Конфигурация

#### pytest.ini (Backend)
```ini
[pytest]
DJANGO_SETTINGS_MODULE = config.settings.testing
python_files = tests.py test_*.py *_tests.py
python_classes = Test*
python_functions = test_*
addopts = 
    --cov=.
    --cov-report=html
    --cov-report=term
    --cov-fail-under=80
    -v
```

#### playwright.config.ts (E2E)
```typescript
import { defineConfig } from '@playwright/test';

export default defineConfig({
  testDir: './e2e',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: 'html',
  use: {
    baseURL: process.env.STAGING_URL || 'http://localhost:3000',
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
  },
  projects: [
    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },
    { name: 'firefox', use: { ...devices['Desktop Firefox'] } },
    { name: 'webkit', use: { ...devices['Desktop Safari'] } },
  ],
});
```

#### k6 script example (Load Testing)
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 }, // Ramp-up
    { duration: '5m', target: 100 }, // Stay at 100 users
    { duration: '2m', target: 0 },   // Ramp-down
  ],
  thresholds: {
    http_req_duration: ['p(95)<800'], // 95% of requests must be below 800ms
    http_req_failed: ['rate<0.01'],   // Error rate < 1%
  },
};

export default function () {
  const res = http.get('https://api.example.com/v1/services');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 800ms': (r) => r.timings.duration < 800,
  });
  sleep(1);
}
```

---

## 8) Отчетность и метрики

### 8.1 Отчеты

#### 8.1.1 Интеграционное тестирование
- **Отчет о покрытии:** процент покрытия по модулям
- **Список тестов:** пройденные/проваленные тесты
- **Найденные проблемы:** список багов с приоритетами

#### 8.1.2 E2E тестирование
- **Отчет Playwright:** HTML отчет с скриншотами и видео
- **Статистика:** pass/fail rate, время выполнения
- **Flaky tests:** список нестабильных тестов

#### 8.1.3 Нагрузочное тестирование
- **Отчет k6:** метрики производительности (latency, throughput, error rate)
- **Графики:** визуализация нагрузки и метрик
- **Выявленные узкие места:** рекомендации по оптимизации

#### 8.1.4 Security Audit
- **Отчет OWASP ZAP:** список уязвимостей с severity
- **Отчет dependency scanning:** уязвимые зависимости
- **План исправления:** приоритизированный список исправлений

#### 8.1.5 A11y проверка
- **Отчет axe/Lighthouse:** список проблем доступности
- **Ручная проверка:** результаты проверки с клавиатуры и screen reader
- **План исправления:** приоритизированный список исправлений

#### 8.1.6 Общий отчет Phase 7
- **Executive Summary:** краткое резюме результатов
- **Метрики:** сводка всех метрик (SLO, покрытие, баги)
- **Риски:** выявленные риски и митигация
- **Рекомендации:** рекомендации перед Go Live

### 8.2 Метрики прогресса

**Ежедневные метрики:**
- Количество пройденных тестов
- Количество найденных багов (по severity)
- Процент покрытия кода
- Процент соответствия SLO

**Итоговые метрики:**
- Все критерии готовности выполнены (да/нет)
- Процент готовности Phase 7
- Оценка времени до завершения

---

## 9) Риски и митигация

### 9.1 Риски

#### Риск 1: Недостаточное покрытие тестами
**Вероятность:** Средняя  
**Влияние:** Высокое  
**Митигация:**
- Раннее начало написания тестов (параллельно с разработкой)
- Автоматическая проверка покрытия в CI/CD
- Code review требует тесты для новых фич

#### Риск 2: Flaky E2E тесты
**Вероятность:** Высокая  
**Влияние:** Среднее  
**Митигация:**
- Использование стабильных селекторов
- Retry logic для нестабильных операций
- Изоляция тестов (каждый тест независим)
- Мониторинг flaky rate

#### Риск 3: Несоответствие SLO
**Вероятность:** Средняя  
**Влияние:** Высокое  
**Митигация:**
- Раннее нагрузочное тестирование (до Phase 7)
- Профилирование и оптимизация узких мест
- Масштабирование инфраструктуры при необходимости

#### Риск 4: Критичные уязвимости безопасности
**Вероятность:** Низкая  
**Влияние:** Критичное  
**Митигация:**
- Регулярное сканирование зависимостей (в CI/CD)
- Code review с фокусом на безопасность
- Ранний security audit (до Phase 7)

#### Риск 5: Проблемы с доступностью
**Вероятность:** Средняя  
**Влияние:** Среднее  
**Митигация:**
- Интеграция автоматических проверок в CI/CD
- Ручная проверка на этапе разработки
- Использование Design System с встроенной доступностью

#### Риск 6: Задержки в исправлении багов
**Вероятность:** Средняя  
**Влияние:** Высокое  
**Митигация:**
- Приоритизация багов (блокеры исправляются немедленно)
- Параллельная работа над исправлениями
- Workaround для некритичных багов

### 9.2 Эскалация

**Критерии эскалации:**
- Блокер (P0) баг найден → немедленная эскалация Product Owner
- Критичная уязвимость безопасности → немедленная эскалация Security team
- Несоответствие SLO после оптимизации → эскалация Architect/DevOps
- Задержка Phase 7 > 1 неделя → эскалация Project Manager

---

## 10) Чеклист готовности Phase 7

### 10.1 Интеграционное тестирование
- [ ] Все интеграционные тесты написаны/обновлены
- [ ] Покрытие ≥80% для критичных модулей
- [ ] Все тесты проходят (≥95% pass rate)
- [ ] Найденные проблемы задокументированы

### 10.2 E2E тестирование
- [ ] E2E тесты для всех P0 сценариев написаны
- [ ] 100% pass rate для P0 сценариев
- [ ] ≥95% pass rate для всех E2E тестов
- [ ] Flaky tests ≤ 2%

### 10.3 Нагрузочное тестирование
- [ ] Все сценарии нагрузки протестированы
- [ ] Все SLO выполнены
- [ ] Узкие места выявлены и оптимизированы
- [ ] Отчет сгенерирован

### 10.4 Security Audit
- [ ] Автоматизированное сканирование выполнено
- [ ] Ручная проверка критичных endpoints выполнена
- [ ] 0 критичных уязвимостей
- [ ] ≤3 высоких уязвимостей (с планом исправления)
- [ ] Отчет сгенерирован

### 10.5 A11y проверка
- [ ] Автоматизированная проверка выполнена
- [ ] Ручная проверка с клавиатуры выполнена
- [ ] Ручная проверка с screen reader выполнена
- [ ] ≥95% соответствие WCAG 2.2 AA
- [ ] Отчет сгенерирован

### 10.6 Исправление багов
- [ ] 0 блокеров (P0)
- [ ] ≤5 критичных (P1) с планом исправления
- [ ] Все высокие (P2) исправлены или имеют workaround
- [ ] Регрессионное тестирование пройдено

### 10.7 Документация
- [ ] Все отчеты сгенерированы
- [ ] Метрики задокументированы
- [ ] Известные ограничения задокументированы
- [ ] Общий отчет Phase 7 подготовлен

---

## 11) Следующие шаги

После завершения Phase 7:

1. ✅ Переход к Phase 8: Deployment & Go Live
2. ✅ Использование отчетов Phase 7 для планирования Phase 8
3. ✅ Документирование lessons learned
4. ✅ Обновление документации на основе результатов тестирования

---

## 12) Ссылки и ресурсы

### Внутренние документы
- `docs/Development-Phase-Plan.md` — план стадии Development
- `docs/NFR-SLO-SLI-Performance-Security-Scalability.md` — требования к производительности и безопасности
- `docs/security/security-requirements.md` — требования безопасности
- `docs/Accessibility-A11y-Requirements.md` — требования доступности
- `docs/user-flows-cjm.md` — пользовательские сценарии
- `docs/Roadmap-Backlog.md` — roadmap и backlog

### Внешние ресурсы
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [WCAG 2.2 Guidelines](https://www.w3.org/WAI/WCAG22/quickref/)
- [Playwright Documentation](https://playwright.dev/)
- [k6 Documentation](https://k6.io/docs/)
- [OWASP ZAP Documentation](https://www.zaproxy.org/docs/)

---

**Версия:** v1.0  
**Последнее обновление:** 2026-01-26  
**Статус:** ✅ Спецификация готова к использованию
